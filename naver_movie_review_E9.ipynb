{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영화리뷰 텍스트 감성분석하기\n",
    "\n",
    "### 학습목표\n",
    "- 텍스트 데이터를 머신러닝 입출력용 수치데이터로 변환하는 과정을 이해한다.\n",
    "- RNN의 특징을 이해하고 시퀀셜한 데이터를 다루는 방법을 이해한다.\n",
    "- 1-D CNN으로도 텍스트를 처리할 수 있음을 이해한다.\n",
    "- IMDB와 네이버 영화리뷰 데이터셋을 이용한 영화리뷰 감성분류 실습을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 데이터의 특징 (1) 텍스트를 숫자로 표현하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "# 우리의 텍스트 데이터로부터 사전을 만들기 위해 모든 문장을 단어 단위로 쪼갠 후에 파이썬 딕셔너리(dict) 자료구조로 표현해 보겠습니다.\n",
    "\n",
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "# 텍스트를 숫자로 바꾸려면 위의 딕셔너리가 {텍스트:인덱스} 구조로 만들기\n",
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# 딕셔너리는 단어를 주면 그 단어의 인덱스를 반환하는 방식으로 사용\n",
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 데이터를 숫자로 바꿔 표현해 봅시다.\n",
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 데이터의 특징 (2) Embedding 레이어의 등장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.02884325  0.0323563  -0.01087039 -0.0218204 ]\n",
      "  [-0.00959275 -0.02911035  0.0483732   0.03494759]\n",
      "  [ 0.01841403  0.03676256 -0.02922511 -0.00813949]\n",
      "  [-0.03681504 -0.01195597 -0.04270029  0.00373822]\n",
      "  [-0.02058859 -0.04647559  0.00645499 -0.03575699]]\n",
      "\n",
      " [[ 0.02884325  0.0323563  -0.01087039 -0.0218204 ]\n",
      "  [-0.00959275 -0.02911035  0.0483732   0.03494759]\n",
      "  [ 0.0388009  -0.02245009 -0.03801974 -0.02875713]\n",
      "  [ 0.02862697 -0.00169996 -0.00982492 -0.03730832]\n",
      "  [-0.02058859 -0.04647559  0.00645499 -0.03575699]]\n",
      "\n",
      " [[ 0.02884325  0.0323563  -0.01087039 -0.0218204 ]\n",
      "  [ 0.03206691 -0.00120597 -0.00111275  0.00877213]\n",
      "  [-0.00959275 -0.02911035  0.0483732   0.03494759]\n",
      "  [ 0.01841403  0.03676256 -0.02922511 -0.00813949]\n",
      "  [ 0.04169781  0.01735575  0.0236916  -0.01884592]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "# list 형태의 sentences는 numpy array로 변환되어야 딥러닝 레이어의 입력이 될 수 있습니다.\n",
    "\n",
    "# Tensorflow에서는 keras.preprocessing.sequence.pad_sequences라는 편리한 함수를 통해 \n",
    "# 문장 벡터 뒤에 패딩(<PAD>)을 추가하여 길이를 일정하게 맞춰주는 기능을 제공합니다.\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시퀀스 데이터를 다루는 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델을 사용하여 이전 스텝의 텍스트 데이터를 처리하는 예제코드\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 꼭 RNN이어야 할까?\n",
    "\n",
    "텍스트를 처리하기 위해 RNN이 아니라 1-D Convolution Neural Network(1-D CNN)을 사용할 수도 있습니다. 우리는 이미지 분류기를 구현하면서 2-D CNN을 이미 사용해 본 바 있습니다. 이미지는 시퀀스 데이터가 아닙니다. 이미지 분류기 모델에는 이미지 전체가 한꺼번에 입력으로 사용됩니다. 그러므로 1-D CNN은 문장 전체를 한꺼번에 한 방향으로 길이 7짜리 필터로 스캐닝하면서 7단어 이내에서 발견되는 특징을 추출하여 그것으로 문장을 분류하는 방식으로 사용됩니다. 이 방식도 텍스트를 처리하는 데 RNN 못지않은 효율을 보여줍니다. 그리고 CNN 계열은 RNN 계열보다 병렬처리가 효율적이기 때문에 학습속도도 훨씬 빠르게 진행된다는 장점이 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 아주 간단히는 GlobalMaxPooling1D() 레이어 하나만 사용하는 방법도 생각해 볼 수 있습니다. \n",
    "# 이 방식은 전체 문장 중에서 단 하나의 가장 중요한 단어만 피처로 추출하여 그것으로 문장의 긍정/부정을 평가하는 방식이라고 생각할 수 있는데, \n",
    "# 의외로 성능이 잘 나올 수도 있습니다.\n",
    "\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 영화리뷰 감성분석 (1) IMDB 데이터셋 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDB 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "# imdb.load_data() 호출시 단어사전에 등재할 단어의 개수(num_words)를 10000으로 지정하면, \n",
    "# 그 개수만큼의 word_to_index 딕셔너리까지 생성된 형태로 데이터셋이 생성됩니다.\n",
    "\n",
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 데이터가 아니라 이미 숫자로 encode된 텍스트 데이터를 다운로드받았음을 확인할 수 있습니다.\n",
    "# 이미 텍스트가 encode되었으므로 IMDB 데이터셋에는 encode에 사용한 딕셔너리까지 함께 제공합니다.\n",
    "\n",
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "# MDB 데이터셋의 텍스트 인코딩을 위한 word_to_index, index_to_word는 아래와 같이 보정되어야 합니다. \n",
    "# 아래 내용은 Tensorflow 튜토리얼의 가이드를 반영하여 작성하였습니다.\n",
    "# word_to_index는 IMDB 텍스트 데이터셋의 단어 출현 빈도 기준으로 내림차수 정렬되어 있습니다.\n",
    "\n",
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "# 다운받은 데이터셋이 확인되었습니다. 마지막으로, encode된 텍스트가 정상적으로 decode되는지 확인해 보겠습니다.\n",
    "\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "# pad_sequences를 통해 데이터셋 상의 문장의 길이를 통일하는 것을 잊어서는 안됩니다.\n",
    "# 문장 최대 길이 maxlen의 값 설정도 전체 모델 성능에 영향을 미치게 됩니다. \n",
    "# 이 길이도 적절한 값을 찾기 위해서는 전체 데이터셋의 분포를 확인해 보는 것이 좋습니다.\n",
    "\n",
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "# 위의 경우에는 maxlen=580이 됩니다.\n",
    "# 또 한가지 유의해야 하는 것은 padding 방식을 문장 뒷쪽('post')과 앞쪽('pre') 중 어느쪽으로 하느냐에 따라 \n",
    "# RNN을 이용한 딥러닝 적용 시 성능 차이가 발생한다는 점입니다.\n",
    "# 두 가지 방식을 한번씩 다 적용해서 RNN을 학습시켜 보면서 그 결과를 비교해 보시기 바랍니다.\n",
    "\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'post'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'post'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "# 위의 경우에는 maxlen=580이 됩니다.\n",
    "# 또 한가지 유의해야 하는 것은 padding 방식을 문장 뒷쪽('post')과 앞쪽('pre') 중 어느쪽으로 하느냐에 따라 \n",
    "# RNN을 이용한 딥러닝 적용 시 성능 차이가 발생한다는 점입니다.\n",
    "# 두 가지 방식을 한번씩 다 적용해서 RNN을 학습시켜 보면서 그 결과를 비교해 보시기 바랍니다.\n",
    "\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 영화리뷰 감성분석 (2) 딥러닝 모델 설계와 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,145\n",
      "Trainable params: 160,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델을 직접 설계해 보자\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# 우리가 사용할 수 있는 모델에는 RNN만 있는 것이 아닙니다. 이전 스텝에서 구현해 본 다양한 모델들이 전부 사용 가능합니다.\n",
    "\n",
    "# model 훈련 전에, 훈련용 데이터셋 25000건 중 10000건을 분리하여 검증셋(validation set)으로 사용하도록 합니다. \n",
    "# 적절한 validation 데이터는 몇 개가 좋을지 고민해 봅시다.\n",
    "\n",
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.6911 - accuracy: 0.6443 - val_loss: 0.6869 - val_accuracy: 0.7249\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.6787 - accuracy: 0.7161 - val_loss: 0.6710 - val_accuracy: 0.7237\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.6573 - accuracy: 0.7679 - val_loss: 0.6480 - val_accuracy: 0.7648\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.6265 - accuracy: 0.8076 - val_loss: 0.6160 - val_accuracy: 0.7835\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.5850 - accuracy: 0.8263 - val_loss: 0.5755 - val_accuracy: 0.8036\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.5352 - accuracy: 0.8409 - val_loss: 0.5308 - val_accuracy: 0.8107\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.4823 - accuracy: 0.8524 - val_loss: 0.4877 - val_accuracy: 0.8206\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.4317 - accuracy: 0.8649 - val_loss: 0.4504 - val_accuracy: 0.8270\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3871 - accuracy: 0.8754 - val_loss: 0.4207 - val_accuracy: 0.8336\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3495 - accuracy: 0.8839 - val_loss: 0.3987 - val_accuracy: 0.8383\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3186 - accuracy: 0.8921 - val_loss: 0.3829 - val_accuracy: 0.8413\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2927 - accuracy: 0.8999 - val_loss: 0.3719 - val_accuracy: 0.8433\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2705 - accuracy: 0.9086 - val_loss: 0.3636 - val_accuracy: 0.8440\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2504 - accuracy: 0.9151 - val_loss: 0.3559 - val_accuracy: 0.8462\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2310 - accuracy: 0.9220 - val_loss: 0.3508 - val_accuracy: 0.8459\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2131 - accuracy: 0.9285 - val_loss: 0.3478 - val_accuracy: 0.8471\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1970 - accuracy: 0.9338 - val_loss: 0.3465 - val_accuracy: 0.8467\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1825 - accuracy: 0.9395 - val_loss: 0.3464 - val_accuracy: 0.8475\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1692 - accuracy: 0.9446 - val_loss: 0.3477 - val_accuracy: 0.8463\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1570 - accuracy: 0.9499 - val_loss: 0.3492 - val_accuracy: 0.8465\n"
     ]
    }
   ],
   "source": [
    "# model 학습을 시작해 봅시다.\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 1s - loss: 0.3619 - accuracy: 0.8426\n",
      "[0.3618706166744232, 0.8426399827003479]\n"
     ]
    }
   ],
   "source": [
    "# 학습이 끝난 모델을 테스트셋으로 평가해 봅니다.\n",
    "\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# model.fit() 과정 중의 train/validation loss, accuracy 등이 매 epoch마다 history 변수에 저장되어 있습니다.\n",
    "# 이 데이터를 그래프로 그려 보면, 수행했던 딥러닝 학습이 잘 진행되었는지, 오버피팅 혹은 언더피팅하지 않았는지, \n",
    "# 성능을 개선할 수 있는 다양한 아이디어를 얻을 수 있는 좋은 자료가 됩니다.\n",
    "\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and validation loss를 그려 보면, 몇 epoch까지의 트레이닝이 적절한지 최적점을 추정해 볼 수 있습니다. \n",
    "# validation loss의 그래프가 train loss와의 이격이 발생하게 되면 더이상의 트레이닝은 무의미해지게 마련입니다.\n",
    "# 마찬가지로 Training and validation accuracy를 그려 보아도 유사한 인사이트를 얻을 수 있습니다.\n",
    "\n",
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 영화리뷰 감성분석 (3) Word2Vec의 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (2.1.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: boto3 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.14.52)\n",
      "Requirement already satisfied: boto in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.52 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.52)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.52->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.52->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "# 워드벡터를 다루는데 유용한 gensim 패키기 설치함\n",
    "# mkdir -p -~/aiffel/sentimental_classification\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/naver_movie_review/sentimental_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02946928, -0.02853395, -0.02435401, -0.04404843, -0.02059644,\n",
       "       -0.04887279, -0.0268178 , -0.02948667, -0.02386098,  0.0216036 ,\n",
       "       -0.02874109, -0.02055578, -0.0187801 , -0.02839378,  0.03932932,\n",
       "       -0.04726087], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coming', 0.9838578701019287),\n",
       " ('negative', 0.9832875728607178),\n",
       " ('training', 0.9829071164131165),\n",
       " ('art', 0.9824705719947815),\n",
       " ('roman', 0.9823288917541504),\n",
       " ('disturbing', 0.9815885424613953),\n",
       " ('sound', 0.9797816276550293),\n",
       " ('passes', 0.9792391061782837),\n",
       " (\"isn't\", 0.9787222743034363),\n",
       " ('yes', 0.9783115386962891)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Google의 Word2Vec 모델을 가져와 적용해 봅시다.\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/naver_movie_review/sentimental_classification/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-dd9d7cdfb11f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilar_by_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"love\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 스텝에서 학습했던 모델의 임베딩 레이어를 Word2Vec의 것으로 교체하여 다시 학습시켜 볼 것입니다. \n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 23s 762ms/step - loss: 0.6934 - accuracy: 0.5185 - val_loss: 0.6834 - val_accuracy: 0.5618\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.6577 - accuracy: 0.6132 - val_loss: 0.6458 - val_accuracy: 0.6283\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 6s 201ms/step - loss: 0.5562 - accuracy: 0.7363 - val_loss: 0.4925 - val_accuracy: 0.7756\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.3701 - accuracy: 0.8519 - val_loss: 0.4049 - val_accuracy: 0.8141\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.2656 - accuracy: 0.8970 - val_loss: 0.3345 - val_accuracy: 0.8566\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.1915 - accuracy: 0.9323 - val_loss: 0.3292 - val_accuracy: 0.8606\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.1405 - accuracy: 0.9567 - val_loss: 0.3228 - val_accuracy: 0.8679\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.0958 - accuracy: 0.9776 - val_loss: 0.3498 - val_accuracy: 0.8607\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.0669 - accuracy: 0.9887 - val_loss: 0.3460 - val_accuracy: 0.8694\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.0431 - accuracy: 0.9951 - val_loss: 0.3670 - val_accuracy: 0.8688\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.0288 - accuracy: 0.9985 - val_loss: 0.3779 - val_accuracy: 0.8693\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.0203 - accuracy: 0.9993 - val_loss: 0.3985 - val_accuracy: 0.8685\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.0146 - accuracy: 0.9995 - val_loss: 0.4157 - val_accuracy: 0.8688\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.0109 - accuracy: 0.9995 - val_loss: 0.4290 - val_accuracy: 0.8685\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.0084 - accuracy: 0.9997 - val_loss: 0.4436 - val_accuracy: 0.8685\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 6s 201ms/step - loss: 0.0063 - accuracy: 0.9999 - val_loss: 0.4577 - val_accuracy: 0.8682\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 6s 201ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.4713 - val_accuracy: 0.8676\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 6s 201ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.4820 - val_accuracy: 0.8677\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.4931 - val_accuracy: 0.8673\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.5036 - val_accuracy: 0.8676\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 9s - loss: 0.5549 - accuracy: 0.8546\n",
      "[0.5548879504203796, 0.854640007019043]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 : 네이버 영화리뷰 감성분석 도전하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/naver_movie_review/sentimental_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/naver_movie_review/sentimental_classification/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        150000 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     150000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 데이터로더 구성\n",
    "- tokenizer는 Mecab을 사용\n",
    "- 불용어도 간단하게 정의 후 전처리에 사용\n",
    "- word_to_index생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "\n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index_to_word생성\n",
    "- word_to_index를 활용해서 새로운 index_to_word생성\n",
    "- 그외에 인덱스를 입력하면 단어로 리턴해주는 함수, 단어를 입력하면 인덱스로 리턴해주는 함수를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 모델구성을 위한 데이터 분석 및 가공\n",
    "- 데이터셋 내 문장 길이 분포\n",
    "- 적절한 최대 문장 길이 지정\n",
    "- keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.969376315021577\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843535456326455\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49157, 41)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 모델구성 및 validation set 구성\n",
    "\n",
    "파라미터를 고정하여 3가지 모델로 학습\n",
    "- 1-D CNN\n",
    "- LSTM\n",
    "- GlobalMaxPooling1D\n",
    "이후에 가장 성능이 좋은 모델 선택 후 파라미터 튜닝을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146182"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126182, 41)\n",
      "(126182,)\n",
      "(20000, 41)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 20000건 분리\n",
    "x_val = X_train[:20000]   \n",
    "y_val = y_train[:20000]\n",
    "\n",
    "# validation set을 제외한 나머지\n",
    "partial_X_train = X_train[20000:]  \n",
    "partial_y_train = y_train[20000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세가지 모델을 평가할 때, 파라미터는 고정으로 사용\n",
    "vocab_size = len(index_to_word)\n",
    "word_vector_dim = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 256)         537856    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 64)          114752    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,653,137\n",
      "Trainable params: 3,653,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# CNN\n",
    "CNN_model = keras.Sequential(name=\"CNN\")\n",
    "CNN_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "CNN_model.add(keras.layers.Conv1D(256, 7, activation='relu'))\n",
    "CNN_model.add(keras.layers.MaxPooling1D(5))\n",
    "CNN_model.add(keras.layers.Conv1D(64, 7, activation='relu'))\n",
    "CNN_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "CNN_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "CNN_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 9888      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,009,969\n",
      "Trainable params: 3,009,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "\n",
    "LSTM_model = keras.Sequential(name=\"LSTM\")\n",
    "LSTM_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "LSTM_model.add(keras.layers.LSTM(8, dropout=0.7))\n",
    "LSTM_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "LSTM_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GMP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 2408      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,002,417\n",
      "Trainable params: 3,002,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GlobalMaxPooling1D\n",
    "\n",
    "GMP_model = keras.Sequential(name=\"GMP\")\n",
    "GMP_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "GMP_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "GMP_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "GMP_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "GMP_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3가지 모델을 같은 조건에서 학습 후 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN', 'LSTM', 'GMP']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lst = [CNN_model.name, LSTM_model.name, GMP_model.name]\n",
    "model_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Start fitting CNN ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 27s 110ms/step - loss: 0.4035 - accuracy: 0.8085 - val_loss: 0.3278 - val_accuracy: 0.8569\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.2835 - accuracy: 0.8814 - val_loss: 0.3274 - val_accuracy: 0.8611\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.2050 - accuracy: 0.9196 - val_loss: 0.3532 - val_accuracy: 0.8593\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.1239 - accuracy: 0.9552 - val_loss: 0.4333 - val_accuracy: 0.8479\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0737 - accuracy: 0.9749 - val_loss: 0.5324 - val_accuracy: 0.8504\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0462 - accuracy: 0.9847 - val_loss: 0.6507 - val_accuracy: 0.8454\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0370 - accuracy: 0.9870 - val_loss: 0.7118 - val_accuracy: 0.8472\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0342 - accuracy: 0.9879 - val_loss: 0.7835 - val_accuracy: 0.8453\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0331 - accuracy: 0.9879 - val_loss: 0.8497 - val_accuracy: 0.8435\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.8739 - val_accuracy: 0.8439\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0195 - accuracy: 0.9931 - val_loss: 1.0201 - val_accuracy: 0.8411\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0193 - accuracy: 0.9927 - val_loss: 1.0031 - val_accuracy: 0.8391\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0220 - accuracy: 0.9923 - val_loss: 0.9619 - val_accuracy: 0.8457\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0173 - accuracy: 0.9934 - val_loss: 1.0897 - val_accuracy: 0.8435\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0151 - accuracy: 0.9939 - val_loss: 1.1063 - val_accuracy: 0.8396\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0173 - accuracy: 0.9935 - val_loss: 1.1176 - val_accuracy: 0.8439\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0123 - accuracy: 0.9952 - val_loss: 1.1727 - val_accuracy: 0.8399\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 1.2344 - val_accuracy: 0.8437\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0116 - accuracy: 0.9951 - val_loss: 1.2344 - val_accuracy: 0.8445\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 9s 36ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 1.2516 - val_accuracy: 0.8444\n",
      "Start evaluating CNN ...\n",
      "1537/1537 - 8s - loss: 1.3066 - accuracy: 0.8394\n",
      "----------------------------------------\n",
      "Start fitting LSTM ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.5843 - accuracy: 0.6561 - val_loss: 0.3808 - val_accuracy: 0.8392\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.3647 - accuracy: 0.8465 - val_loss: 0.3444 - val_accuracy: 0.8504\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 8s 31ms/step - loss: 0.3291 - accuracy: 0.8626 - val_loss: 0.3393 - val_accuracy: 0.8522\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.3082 - accuracy: 0.8711 - val_loss: 0.3347 - val_accuracy: 0.8562\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 8s 32ms/step - loss: 0.2933 - accuracy: 0.8771 - val_loss: 0.3425 - val_accuracy: 0.8516\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.2803 - accuracy: 0.8826 - val_loss: 0.3474 - val_accuracy: 0.8554\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.2658 - accuracy: 0.8899 - val_loss: 0.3437 - val_accuracy: 0.8559\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.2556 - accuracy: 0.8944 - val_loss: 0.3440 - val_accuracy: 0.8579\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.2449 - accuracy: 0.8994 - val_loss: 0.3518 - val_accuracy: 0.8573\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.2346 - accuracy: 0.9035 - val_loss: 0.3558 - val_accuracy: 0.8584\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.2270 - accuracy: 0.9070 - val_loss: 0.3559 - val_accuracy: 0.8584\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 8s 30ms/step - loss: 0.2200 - accuracy: 0.9102 - val_loss: 0.3668 - val_accuracy: 0.8540\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.2119 - accuracy: 0.9134 - val_loss: 0.3682 - val_accuracy: 0.8583\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.2054 - accuracy: 0.9152 - val_loss: 0.3989 - val_accuracy: 0.8571\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.2005 - accuracy: 0.9182 - val_loss: 0.3969 - val_accuracy: 0.8543\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.1942 - accuracy: 0.9209 - val_loss: 0.3870 - val_accuracy: 0.8565\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.1914 - accuracy: 0.9220 - val_loss: 0.3902 - val_accuracy: 0.8563\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.1857 - accuracy: 0.9242 - val_loss: 0.3984 - val_accuracy: 0.8560\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.1828 - accuracy: 0.9260 - val_loss: 0.4225 - val_accuracy: 0.8541\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.1785 - accuracy: 0.9283 - val_loss: 0.4221 - val_accuracy: 0.8558\n",
      "Start evaluating LSTM ...\n",
      "1537/1537 - 2s - loss: 0.4248 - accuracy: 0.8528\n",
      "----------------------------------------\n",
      "Start fitting GMP ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 7s 28ms/step - loss: 0.4771 - accuracy: 0.7777 - val_loss: 0.3443 - val_accuracy: 0.8492\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.3110 - accuracy: 0.8691 - val_loss: 0.3319 - val_accuracy: 0.8545\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.2630 - accuracy: 0.8933 - val_loss: 0.3385 - val_accuracy: 0.8551\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.2200 - accuracy: 0.9140 - val_loss: 0.3533 - val_accuracy: 0.8543\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.1755 - accuracy: 0.9365 - val_loss: 0.3812 - val_accuracy: 0.8547\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 7s 28ms/step - loss: 0.1301 - accuracy: 0.9572 - val_loss: 0.4156 - val_accuracy: 0.8511\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 7s 28ms/step - loss: 0.0902 - accuracy: 0.9740 - val_loss: 0.4602 - val_accuracy: 0.8484\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.0602 - accuracy: 0.9849 - val_loss: 0.5017 - val_accuracy: 0.8469\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.0407 - accuracy: 0.9903 - val_loss: 0.5466 - val_accuracy: 0.8442\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.0289 - accuracy: 0.9934 - val_loss: 0.5830 - val_accuracy: 0.8418\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 7s 28ms/step - loss: 0.0213 - accuracy: 0.9947 - val_loss: 0.6246 - val_accuracy: 0.8412\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.6496 - val_accuracy: 0.8429\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 8s 30ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.6730 - val_accuracy: 0.8438\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.7033 - val_accuracy: 0.8414\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 7s 28ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.7215 - val_accuracy: 0.8426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "247/247 [==============================] - 7s 28ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.7456 - val_accuracy: 0.8436\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.0089 - accuracy: 0.9964 - val_loss: 0.7609 - val_accuracy: 0.8425\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 7s 28ms/step - loss: 0.0083 - accuracy: 0.9966 - val_loss: 0.7847 - val_accuracy: 0.8414\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 7s 28ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 0.7954 - val_accuracy: 0.8434\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 7s 28ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.8122 - val_accuracy: 0.8418\n",
      "Start evaluating GMP ...\n",
      "1537/1537 - 2s - loss: 0.8253 - accuracy: 0.8388\n"
     ]
    }
   ],
   "source": [
    "model_result = {}\n",
    "\n",
    "for model_name in model_lst:\n",
    "    \n",
    "    if model_name == \"CNN\":\n",
    "        model = CNN_model\n",
    "    elif model_name == \"LSTM\":\n",
    "        model = LSTM_model\n",
    "    else :\n",
    "        model = GMP_model\n",
    "    \n",
    "    print('-'*40)\n",
    "    print(\"Start fitting {} ...\".format(model_name))\n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    epochs=20\n",
    "\n",
    "    history = model.fit(partial_X_train,\n",
    "                        partial_y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=512,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        verbose=1)\n",
    "    \n",
    "    \n",
    "    print(\"Start evaluating {} ...\".format(model_name))\n",
    "    results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "    model_result[model_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM \t 0.8527778387069702\n",
      "CNN \t 0.83941251039505\n",
      "GMP \t 0.8388022184371948\n"
     ]
    }
   ],
   "source": [
    "for name, [_, acc] in sorted(model_result.items(), key=lambda x : x[1][1], reverse=True) :\n",
    "    print(name,'\\t',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 모델 훈련 개시\n",
    "\n",
    "위의 모델 중에서 LSTM의 성능이 가장 좋았다.\n",
    "모델을 훈련하기 전에 먼저 성능을 올릴 수 있는 최적의 하이퍼파라미터를 찾아본다.\n",
    "\n",
    "### 최적의 모델 만들기\n",
    "\n",
    "- LSTM모델 앞에 CNN을 추가도 해보았고, LSTM을 추가도 해보았다.\n",
    "- CNN의 경우는 추가를 하면 성능이 더 나빴다.\n",
    "- LSTM층을 하나 더 추가할 경우 결과는 크게 달라지지 않았지만 학습 곡선이 다르게 나타나는 것을 알 수 있었다.\n",
    "- 간단하게 LSTM 레이어 하나만을 사용해서 하이퍼파라미터를 튜닝해보도록 하였다.\n",
    "- word_vector_dim 을 늘려가면서 성능이 점점 더 좋아지는 것을 알 수 있었다.\n",
    ": 1000\n",
    "- LSTM 레이어의 벡터 차원수를 기존에 8에서 128까지 늘렸다.\n",
    ": input dimension이 1000개에 반해 128개의 차원은 여전히 부족하지 않을까?\n",
    "- Overfitting이 자주 발생하여서 LSTM의 인자로 Dropout도 추가하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, None, 1000)        10000000  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               578048    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 10,579,089\n",
      "Trainable params: 10,579,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word_vector_dim = 1000  # 워드 벡터의 차원수\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "# CNN을 추가했을 때\n",
    "# model.add(keras.layers.Conv1D(8, 7, activation='relu'))\n",
    "# model.add(keras.layers.MaxPooling1D())\n",
    "# LSTM 레이어를 두개로 학습했을 때\n",
    "# model.add(keras.layers.LSTM(256, dropout=0.7, return_sequences=True))\n",
    "model.add(keras.layers.LSTM(128, dropout=0.7))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 이진분류\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전에 20번 epoch을 돌리는 동안 validation loss값이 오르는 것을 확인할 수 있었다.(Overfitting 발생)\n",
    "\n",
    "그렇게 때문에 callback의 EarlyStopping을 사용하였고 최적의 모델을 저장하기 위해서 ModelCheckpoint를 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "model_check = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer에서 사용하는 Adam에도 learning rate를 조절해주었다.\n",
    "이전에 세가지 모델을 학습시켜보았을 때 여러번 학습이 진행되기 전에 Overfitting이 발생하였기 때문에 학습률을 낮추었다. 추가적으로 배치사이즈도 더 작게 설정하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.6038 - accuracy: 0.6692\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80390, saving model to model.h5\n",
      "986/986 [==============================] - 80s 81ms/step - loss: 0.6038 - accuracy: 0.6692 - val_loss: 0.4584 - val_accuracy: 0.8039\n",
      "Epoch 2/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8342\n",
      "Epoch 00002: val_accuracy improved from 0.80390 to 0.85200, saving model to model.h5\n",
      "986/986 [==============================] - 81s 82ms/step - loss: 0.3822 - accuracy: 0.8342 - val_loss: 0.3406 - val_accuracy: 0.8520\n",
      "Epoch 3/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.3165 - accuracy: 0.8653\n",
      "Epoch 00003: val_accuracy improved from 0.85200 to 0.85715, saving model to model.h5\n",
      "986/986 [==============================] - 80s 81ms/step - loss: 0.3165 - accuracy: 0.8653 - val_loss: 0.3344 - val_accuracy: 0.8572\n",
      "Epoch 4/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.8795\n",
      "Epoch 00004: val_accuracy improved from 0.85715 to 0.86130, saving model to model.h5\n",
      "986/986 [==============================] - 81s 82ms/step - loss: 0.2851 - accuracy: 0.8795 - val_loss: 0.3264 - val_accuracy: 0.8613\n",
      "Epoch 5/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2598 - accuracy: 0.8914\n",
      "Epoch 00005: val_accuracy improved from 0.86130 to 0.86150, saving model to model.h5\n",
      "986/986 [==============================] - 82s 83ms/step - loss: 0.2598 - accuracy: 0.8914 - val_loss: 0.3307 - val_accuracy: 0.8615\n",
      "Epoch 6/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2383 - accuracy: 0.9008\n",
      "Epoch 00006: val_accuracy improved from 0.86150 to 0.86215, saving model to model.h5\n",
      "986/986 [==============================] - 82s 83ms/step - loss: 0.2383 - accuracy: 0.9008 - val_loss: 0.3307 - val_accuracy: 0.8622\n",
      "Epoch 7/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2169 - accuracy: 0.9101\n",
      "Epoch 00007: val_accuracy improved from 0.86215 to 0.86250, saving model to model.h5\n",
      "986/986 [==============================] - 81s 82ms/step - loss: 0.2169 - accuracy: 0.9101 - val_loss: 0.3592 - val_accuracy: 0.8625\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1,\n",
    "                   callbacks=[early_stopping, model_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.3648 - accuracy: 0.8585\n",
      "[0.36482545733451843, 0.8585145473480225]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 학습시킨 결과 0.842에서 0.86까지 정확도가 상승하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Loss, Accuracy 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# 빨간 실선으로 표시\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# 파란 실선으로 표시\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장\n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/naver_movie_review/sentimental_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim)) # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀작성\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록\n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim을 사용해서 학습시킨 word2vector를 사용해서 대박이라는 단어와 연관성이 있는 단어들을 뽑아보았다.\n",
    "영화리뷰라고 생각해보았을 때, 긍정적인 평가들이 나오는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['대박']\n",
    "# vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('각지', 0.5276776552200317),\n",
       " ('싯', 0.5271451473236084),\n",
       " ('진진', 0.5242579579353333),\n",
       " ('최상', 0.5201584696769714),\n",
       " ('웰메이드', 0.5146491527557373),\n",
       " ('아름다워요', 0.5137757062911987),\n",
       " ('최고', 0.5131483674049377),\n",
       " ('수준급', 0.5086012482643127),\n",
       " ('乃', 0.5080664157867432),\n",
       " ('유머러스', 0.5069366693496704)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"대박\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) 한국어 Word2Vec 임베딩 활용하여 성능개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-trained word vectors\n",
    "- 한국어를 다운로드\n",
    "- 위키피디아를 통해서 만든 Word2Vec를 만든 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word2vec.txt',\n",
       " 'ratings_test.txt',\n",
       " 'GoogleNews-vectors-negative300.bin',\n",
       " 'GoogleNews-vectors-negative300.bin.gz',\n",
       " 'ko.tsv',\n",
       " 'ko.bin',\n",
       " 'ratings_train.txt']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('sentimental_classification/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aiffel0042/aiffel/naver_movie_review/sentimental_classification/ko.tsv'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv('HOME')+'/aiffel/naver_movie_review/sentimental_classification/ko.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/naver_movie_review/sentimental_classification/ko.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "# word2vec = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec.load(word2vec_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12250227, -0.26166117,  0.1601894 ,  0.24988233, -0.19694664,\n",
       "        0.20742898,  0.23358916, -0.08032743,  0.07419734,  0.28976992,\n",
       "        0.05920417, -0.24217431,  0.42650384,  0.37083197,  0.01488842,\n",
       "       -0.15399031,  0.21594983,  0.16782928,  0.04716487, -0.3933347 ,\n",
       "        0.06105555, -0.13588727, -0.0257909 , -0.06074918,  0.04168789,\n",
       "        0.34588724,  0.24693313, -0.05122459,  0.16371667,  0.05747311,\n",
       "       -0.12627307, -0.16464052, -0.29741055,  0.17121391, -0.24180788,\n",
       "       -0.28056645, -0.06616814,  0.15681611,  0.20206362, -0.1660444 ,\n",
       "        0.00203782, -0.2563252 , -0.24074501, -0.63730514,  0.35244125,\n",
       "        0.05436644, -0.14913762, -0.06556495, -0.05610788,  0.11254067,\n",
       "       -0.09251513, -0.28059378,  0.07197419,  0.11595767,  0.15117767,\n",
       "       -0.00541334, -0.128903  ,  0.04034068, -0.22690742,  0.00775241,\n",
       "        0.16708778,  0.10937496, -0.17221814,  0.04758313,  0.321897  ,\n",
       "        0.0646909 ,  0.292136  , -0.07984147,  0.09785581,  0.181296  ,\n",
       "        0.17631158,  0.01031382, -0.43260768,  0.01173338,  0.03490037,\n",
       "       -0.0076601 , -0.06428192, -0.2924691 ,  0.24474835,  0.07950445,\n",
       "       -0.09601387, -0.34834263, -0.17978796,  0.23437631, -0.15391289,\n",
       "        0.01297345, -0.04877474, -0.22579618, -0.06827989, -0.266499  ,\n",
       "       -0.18218975, -0.45568773, -0.19330987,  0.09304521,  0.08007847,\n",
       "       -0.08579313, -0.01735996, -0.20058121, -0.11037695, -0.04257905,\n",
       "       -0.01491661,  0.24702635, -0.06080532,  0.07469252,  0.02070692,\n",
       "        0.20998064, -0.12500262, -0.16058917,  0.13576448, -0.01957137,\n",
       "       -0.03530353,  0.02538178,  0.02707971,  0.02211284,  0.4662458 ,\n",
       "       -0.13323712, -0.31756285, -0.26687905, -0.2932379 ,  0.16787444,\n",
       "       -0.00277177,  0.11576287, -0.0071318 ,  0.04130382, -0.0535576 ,\n",
       "        0.5331611 ,  0.15177174,  0.308193  ,  0.12067769, -0.11636538,\n",
       "       -0.16276449, -0.1450912 , -0.07153927,  0.00982432,  0.16283946,\n",
       "        0.16073047, -0.30461156,  0.06590325,  0.18986021,  0.22578666,\n",
       "       -0.10132927,  0.1319676 , -0.28178945,  0.03667555, -0.02295887,\n",
       "       -0.15407115, -0.3441792 , -0.1218596 , -0.3528504 , -0.14319238,\n",
       "       -0.3211591 ,  0.14814556, -0.10278759,  0.23421551,  0.08331902,\n",
       "        0.00759588,  0.39796677, -0.13322656, -0.33425966, -0.2488725 ,\n",
       "        0.22625662, -0.01530029, -0.1754215 ,  0.06301978, -0.09565204,\n",
       "        0.22803056, -0.09959741, -0.08168349,  0.02098079,  0.09322228,\n",
       "       -0.00068385, -0.18893392,  0.2519263 ,  0.05090755,  0.2681667 ,\n",
       "        0.34096426, -0.18010454,  0.16246942,  0.01820518, -0.0705201 ,\n",
       "        0.08623672, -0.01494653, -0.21275468, -0.0316746 ,  0.26614192,\n",
       "        0.02781401,  0.1385179 ,  0.38353992, -0.08111849,  0.10542663,\n",
       "       -0.19549905,  0.01497585,  0.05798322,  0.02531051, -0.04150281,\n",
       "       -0.12611519, -0.05583593, -0.07526224, -0.08963452,  0.0068798 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = word2vec['대박']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "word_vector_dim = 200\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 만든 임베딩을 여기서 학습하는데 활용한다.\n",
    "모델은 위에서 사용한것과 동일하게 LSTM을 사용하였고 LSTM 레이어의 차원도 128로 설정하였다.\n",
    "여기서 Embedding 레이어에 embedding_matrix로 초기화를 해주었기 때문에 word_vector_dim과 같은 경우는 기존에 초기화 되어있는 임베딩의 차원인 200으로 줘야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 256)               467968    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 8)                 2056      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,470,033\n",
      "Trainable params: 2,470,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000\n",
    "word_vector_dim = 200\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix), \n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "\n",
    "model.add(keras.layers.LSTM(256))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "984/986 [============================>.] - ETA: 0s - loss: 0.6674 - accuracy: 0.5683\n",
      "Epoch 00001: val_accuracy did not improve from 0.86250\n",
      "986/986 [==============================] - 17s 17ms/step - loss: 0.6671 - accuracy: 0.5687 - val_loss: 0.4942 - val_accuracy: 0.7717\n",
      "Epoch 2/20\n",
      "984/986 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8291\n",
      "Epoch 00002: val_accuracy did not improve from 0.86250\n",
      "986/986 [==============================] - 17s 17ms/step - loss: 0.3835 - accuracy: 0.8292 - val_loss: 0.3346 - val_accuracy: 0.8557\n",
      "Epoch 3/20\n",
      "984/986 [============================>.] - ETA: 0s - loss: 0.3015 - accuracy: 0.8709\n",
      "Epoch 00003: val_accuracy improved from 0.86250 to 0.86490, saving model to model.h5\n",
      "986/986 [==============================] - 18s 19ms/step - loss: 0.3014 - accuracy: 0.8710 - val_loss: 0.3141 - val_accuracy: 0.8649\n",
      "Epoch 4/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2645 - accuracy: 0.8903\n",
      "Epoch 00004: val_accuracy improved from 0.86490 to 0.86755, saving model to model.h5\n",
      "986/986 [==============================] - 19s 20ms/step - loss: 0.2645 - accuracy: 0.8903 - val_loss: 0.3154 - val_accuracy: 0.8676\n",
      "Epoch 5/20\n",
      "985/986 [============================>.] - ETA: 0s - loss: 0.2336 - accuracy: 0.9052\n",
      "Epoch 00005: val_accuracy did not improve from 0.86755\n",
      "986/986 [==============================] - 18s 18ms/step - loss: 0.2336 - accuracy: 0.9053 - val_loss: 0.3191 - val_accuracy: 0.8657\n",
      "Epoch 6/20\n",
      "984/986 [============================>.] - ETA: 0s - loss: 0.2013 - accuracy: 0.9200\n",
      "Epoch 00006: val_accuracy did not improve from 0.86755\n",
      "986/986 [==============================] - 17s 18ms/step - loss: 0.2013 - accuracy: 0.9201 - val_loss: 0.3316 - val_accuracy: 0.8633\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20\n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1,\n",
    "                   callbacks=[early_stopping, model_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.3370 - accuracy: 0.8596\n",
      "[0.33697712421417236, 0.8596334457397461]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "# 시각화를 시도한다.\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# 빨간 실선으로 표시\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# 파란 실선으로 표시\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 제출\n",
    "\n",
    "### 프로젝트 루브릭 : 아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "### 평가문항 : 상세기준\n",
    "\n",
    "1. 다양한 방법으로 Text Classification 태스크를 성공적으로 구현하였다.\n",
    ": 3가지 이상의 모델이 성공적으로 시도됨\n",
    "2. gensim을 활용하여 자체학습된 혹은 사전학습된 임베딩 레이어를 분석하였다.\n",
    ": gensim의 유사단어 찾기를 활용하여 자체학습한 임베딩과 사전학습 임베딩을 적절히 분석함\n",
    "3. 한국어 Word2Vec을 활용하여 가시적인 성능향상을 달성했다.\n",
    ": 네이버 영화리뷰 데이터 감성분석 정확도를 90% 이상 달성함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정리\n",
    "- 세가지의 모델을 사용해보았다.\n",
    "1. 1D CNN : 0.8413\n",
    "2. LSTM : 0.8424\n",
    "3. GlobalMaxPooling1D : 0.8402\n",
    "- 그 중에서 제일 좋은 LSTM으로 선택, 모델구조 찾기\n",
    "    - 하이퍼파라미터를 튜닝하기 전에 모델구조에 대해서 생각해 보았다.\n",
    "1. CNN 1D -> LSTM\n",
    "2. LSTM -> LSTM\n",
    "3. LSTM 단일 레이어\n",
    "    - 하지만 CNN을 추가한 경우 생각보다 점수가 낮게 나오고 LSTM 레이어를 두개를 사용해도 성능은 나아지지 않았다.\n",
    "- 하이퍼파라미터 설정\n",
    "    - word_vector_dim = 1000\n",
    "    - LSTM 레이어의 차원 수 = 128, dropout = 0.7 적용\n",
    "    - Adam optimizer의 learning rate = 0.0005\n",
    "    - batch_size = 128\n",
    "- Callback 함수 사용\n",
    "    - EearlyStopping\n",
    "    - Checkpoint\n",
    "- 정확도는 0.8413 -> 0.86 으로 약 2퍼센트 성능 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
