{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영화리뷰 텍스트 감성분석하기\n",
    "\n",
    "### 학습목표\n",
    "- 텍스트 데이터를 머신러닝 입출력용 수치데이터로 변환하는 과정을 이해한다.\n",
    "- RNN의 특징을 이해하고 시퀀셜한 데이터를 다루는 방법을 이해한다.\n",
    "- 1-D CNN으로도 텍스트를 처리할 수 있음을 이해한다.\n",
    "- IMDB와 네이버 영화리뷰 데이터셋을 이용한 영화리뷰 감성분류 실습을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 데이터의 특징 (1) 텍스트를 숫자로 표현하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "# 우리의 텍스트 데이터로부터 사전을 만들기 위해 모든 문장을 단어 단위로 쪼갠 후에 파이썬 딕셔너리(dict) 자료구조로 표현해 보겠습니다.\n",
    "\n",
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "# 텍스트를 숫자로 바꾸려면 위의 딕셔너리가 {텍스트:인덱스} 구조로 만들기\n",
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# 딕셔너리는 단어를 주면 그 단어의 인덱스를 반환하는 방식으로 사용\n",
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 데이터를 숫자로 바꿔 표현해 봅시다.\n",
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 데이터의 특징 (2) Embedding 레이어의 등장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.02699569 -0.04050367  0.03649478 -0.04208957]\n",
      "  [ 0.02466906  0.01608017 -0.04608188  0.03819909]\n",
      "  [-0.00720017 -0.02289227  0.00061829  0.01013391]\n",
      "  [ 0.00234172 -0.00417727  0.04472518  0.02368512]\n",
      "  [-0.0406239   0.01237706  0.02921308  0.02090229]]\n",
      "\n",
      " [[-0.02699569 -0.04050367  0.03649478 -0.04208957]\n",
      "  [ 0.02466906  0.01608017 -0.04608188  0.03819909]\n",
      "  [ 0.02340494 -0.00318795  0.03907523 -0.0220499 ]\n",
      "  [-0.04095005  0.020125   -0.00914884 -0.02594746]\n",
      "  [-0.0406239   0.01237706  0.02921308  0.02090229]]\n",
      "\n",
      " [[-0.02699569 -0.04050367  0.03649478 -0.04208957]\n",
      "  [-0.01543155 -0.02989472 -0.0130441  -0.00603936]\n",
      "  [ 0.02466906  0.01608017 -0.04608188  0.03819909]\n",
      "  [-0.00720017 -0.02289227  0.00061829  0.01013391]\n",
      "  [-0.00144274 -0.03658028 -0.04430955 -0.0274717 ]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "# list 형태의 sentences는 numpy array로 변환되어야 딥러닝 레이어의 입력이 될 수 있습니다.\n",
    "\n",
    "# Tensorflow에서는 keras.preprocessing.sequence.pad_sequences라는 편리한 함수를 통해 \n",
    "# 문장 벡터 뒤에 패딩(<PAD>)을 추가하여 길이를 일정하게 맞춰주는 기능을 제공합니다.\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시퀀스 데이터를 다루는 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델을 사용하여 이전 스텝의 텍스트 데이터를 처리하는 예제코드\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 꼭 RNN이어야 할까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 텍스트를 처리하기 위해 RNN이 아니라 1-D Convolution Neural Network(1-D CNN)을 사용할 수도 있습니다.\n",
    "# 우리는 이미지 분류기를 구현하면서 2-D CNN을 이미 사용해 본 바 있습니다. 이미지는 시퀀스 데이터가 아닙니다. 이미지 분류기 모델에는 이미지 전체가 한꺼번에 입력으로 사용됩니다.\n",
    "# 그러므로 1-D CNN은 문장 전체를 한꺼번에 한 방향으로 길이 7짜리 필터로 스캐닝하면서 7단어 이내에서 발견되는 특징을 추출하여 그것으로 문장을 분류하는 방식으로 사용됩니다. 이 방식도 텍스트를 처리하는 데 RNN 못지않은 효율을 보여줍니다.\n",
    "# 그리고 CNN 계열은 RNN 계열보다 병렬처리가 효율적이기 때문에 학습속도도 훨씬 빠르게 진행된다는 장점이 있습니다.\n",
    "\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 아주 간단히는 GlobalMaxPooling1D() 레이어 하나만 사용하는 방법도 생각해 볼 수 있습니다. \n",
    "# 이 방식은 전체 문장 중에서 단 하나의 가장 중요한 단어만 피처로 추출하여 그것으로 문장의 긍정/부정을 평가하는 방식이라고 생각할 수 있는데, \n",
    "# 의외로 성능이 잘 나올 수도 있습니다.\n",
    "\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 영화리뷰 감성분석 (1) IMDB 데이터셋 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDB 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "# imdb.load_data() 호출시 단어사전에 등재할 단어의 개수(num_words)를 10000으로 지정하면, \n",
    "# 그 개수만큼의 word_to_index 딕셔너리까지 생성된 형태로 데이터셋이 생성됩니다.\n",
    "\n",
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 데이터가 아니라 이미 숫자로 encode된 텍스트 데이터를 다운로드받았음을 확인할 수 있습니다.\n",
    "# 이미 텍스트가 encode되었으므로 IMDB 데이터셋에는 encode에 사용한 딕셔너리까지 함께 제공합니다.\n",
    "\n",
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "# MDB 데이터셋의 텍스트 인코딩을 위한 word_to_index, index_to_word는 아래와 같이 보정되어야 합니다. \n",
    "# 아래 내용은 Tensorflow 튜토리얼의 가이드를 반영하여 작성하였습니다.\n",
    "# word_to_index는 IMDB 텍스트 데이터셋의 단어 출현 빈도 기준으로 내림차수 정렬되어 있습니다.\n",
    "\n",
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "# 다운받은 데이터셋이 확인되었습니다. 마지막으로, encode된 텍스트가 정상적으로 decode되는지 확인해 보겠습니다.\n",
    "\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "# pad_sequences를 통해 데이터셋 상의 문장의 길이를 통일하는 것을 잊어서는 안됩니다.\n",
    "# 문장 최대 길이 maxlen의 값 설정도 전체 모델 성능에 영향을 미치게 됩니다. \n",
    "# 이 길이도 적절한 값을 찾기 위해서는 전체 데이터셋의 분포를 확인해 보는 것이 좋습니다.\n",
    "\n",
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "# 위의 경우에는 maxlen=580이 됩니다.\n",
    "# 또 한가지 유의해야 하는 것은 padding 방식을 문장 뒷쪽('post')과 앞쪽('pre') 중 어느쪽으로 하느냐에 따라 \n",
    "# RNN을 이용한 딥러닝 적용 시 성능 차이가 발생한다는 점입니다.\n",
    "# 두 가지 방식을 한번씩 다 적용해서 RNN을 학습시켜 보면서 그 결과를 비교해 보시기 바랍니다.\n",
    "\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'post'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'post'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "# 위의 경우에는 maxlen=580이 됩니다.\n",
    "# 또 한가지 유의해야 하는 것은 padding 방식을 문장 뒷쪽('post')과 앞쪽('pre') 중 어느쪽으로 하느냐에 따라 \n",
    "# RNN을 이용한 딥러닝 적용 시 성능 차이가 발생한다는 점입니다.\n",
    "# 두 가지 방식을 한번씩 다 적용해서 RNN을 학습시켜 보면서 그 결과를 비교해 보시기 바랍니다.\n",
    "\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 영화리뷰 감성분석 (2) 딥러닝 모델 설계와 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,145\n",
      "Trainable params: 160,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델을 직접 설계해 보자\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# 우리가 사용할 수 있는 모델에는 RNN만 있는 것이 아닙니다. 이전 스텝에서 구현해 본 다양한 모델들이 전부 사용 가능합니다.\n",
    "\n",
    "# model 훈련 전에, 훈련용 데이터셋 25000건 중 10000건을 분리하여 검증셋(validation set)으로 사용하도록 합니다. \n",
    "# 적절한 validation 데이터는 몇 개가 좋을지 고민해 봅시다.\n",
    "\n",
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.6914 - accuracy: 0.5036 - val_loss: 0.6890 - val_accuracy: 0.4980\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.6836 - accuracy: 0.5689 - val_loss: 0.6786 - val_accuracy: 0.5654\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.6672 - accuracy: 0.6329 - val_loss: 0.6594 - val_accuracy: 0.6698\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.6400 - accuracy: 0.7192 - val_loss: 0.6299 - val_accuracy: 0.7255\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.6006 - accuracy: 0.7735 - val_loss: 0.5908 - val_accuracy: 0.7523\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.5522 - accuracy: 0.8057 - val_loss: 0.5476 - val_accuracy: 0.7903\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.4983 - accuracy: 0.8411 - val_loss: 0.4977 - val_accuracy: 0.8194\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.4413 - accuracy: 0.8643 - val_loss: 0.4546 - val_accuracy: 0.8325\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3920 - accuracy: 0.8801 - val_loss: 0.4197 - val_accuracy: 0.8413\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3503 - accuracy: 0.8901 - val_loss: 0.3932 - val_accuracy: 0.8446\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3147 - accuracy: 0.9000 - val_loss: 0.3730 - val_accuracy: 0.8484\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2845 - accuracy: 0.9077 - val_loss: 0.3584 - val_accuracy: 0.8514\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2588 - accuracy: 0.9160 - val_loss: 0.3486 - val_accuracy: 0.8528\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2369 - accuracy: 0.9240 - val_loss: 0.3430 - val_accuracy: 0.8537\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2174 - accuracy: 0.9316 - val_loss: 0.3382 - val_accuracy: 0.8556\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1997 - accuracy: 0.9367 - val_loss: 0.3355 - val_accuracy: 0.8567\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1842 - accuracy: 0.9423 - val_loss: 0.3347 - val_accuracy: 0.8573\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1698 - accuracy: 0.9488 - val_loss: 0.3352 - val_accuracy: 0.8565\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1568 - accuracy: 0.9537 - val_loss: 0.3367 - val_accuracy: 0.8550\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1450 - accuracy: 0.9575 - val_loss: 0.3397 - val_accuracy: 0.8549\n"
     ]
    }
   ],
   "source": [
    "# model 학습을 시작해 봅시다.\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 1s - loss: 0.3710 - accuracy: 0.8401\n",
      "[0.37095019221305847, 0.8401200175285339]\n"
     ]
    }
   ],
   "source": [
    "# 학습이 끝난 모델을 테스트셋으로 평가해 봅니다.\n",
    "\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# model.fit() 과정 중의 train/validation loss, accuracy 등이 매 epoch마다 history 변수에 저장되어 있습니다.\n",
    "# 이 데이터를 그래프로 그려 보면, 수행했던 딥러닝 학습이 잘 진행되었는지, 오버피팅 혹은 언더피팅하지 않았는지, \n",
    "# 성능을 개선할 수 있는 다양한 아이디어를 얻을 수 있는 좋은 자료가 됩니다.\n",
    "\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and validation loss를 그려 보면, 몇 epoch까지의 트레이닝이 적절한지 최적점을 추정해 볼 수 있습니다. \n",
    "# validation loss의 그래프가 train loss와의 이격이 발생하게 되면 더이상의 트레이닝은 무의미해지게 마련입니다.\n",
    "# 마찬가지로 Training and validation accuracy를 그려 보아도 유사한 인사이트를 얻을 수 있습니다.\n",
    "\n",
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 영화리뷰 감성분석 (3) Word2Vec의 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: requests in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
      "Requirement already satisfied: boto in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.14.52)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.52 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.52)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.52->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.52->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "# 워드벡터를 다루는데 유용한 gensim 패키기 설치함\n",
    "# mkdir -p -~/aiffel/sentiment_classification\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0085614 , -0.0311787 , -0.04070874, -0.01616547, -0.02569281,\n",
       "       -0.03988174, -0.0365219 , -0.02879096, -0.0259122 , -0.03458915,\n",
       "       -0.02818281, -0.03462288, -0.03156514, -0.04209683, -0.0192404 ,\n",
       "       -0.0207852 ], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f71eb7fe6c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilar_by_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"love\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Google의 Word2Vec 모델을 가져와 적용해 봅시다.\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 스텝에서 학습했던 모델의 임베딩 레이어를 Word2Vec의 것으로 교체하여 다시 학습시켜 볼 것입니다. \n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 : 네이버 영화리뷰 감성분석 도전하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_9 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,145\n",
      "Trainable params: 160,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 데이터로더 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "\n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.6916 - accuracy: 0.5035 - val_loss: 0.6894 - val_accuracy: 0.4955\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.6848 - accuracy: 0.5575 - val_loss: 0.6807 - val_accuracy: 0.5855\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.6708 - accuracy: 0.6493 - val_loss: 0.6632 - val_accuracy: 0.6838\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.6453 - accuracy: 0.7332 - val_loss: 0.6342 - val_accuracy: 0.7393\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.6044 - accuracy: 0.7813 - val_loss: 0.5893 - val_accuracy: 0.7730\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.5457 - accuracy: 0.8259 - val_loss: 0.5346 - val_accuracy: 0.8128\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.4834 - accuracy: 0.8497 - val_loss: 0.4844 - val_accuracy: 0.8255\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.4258 - accuracy: 0.8669 - val_loss: 0.4429 - val_accuracy: 0.8315\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3758 - accuracy: 0.8788 - val_loss: 0.4102 - val_accuracy: 0.8357\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3342 - accuracy: 0.8896 - val_loss: 0.3873 - val_accuracy: 0.8399\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2997 - accuracy: 0.8991 - val_loss: 0.3709 - val_accuracy: 0.8420\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2709 - accuracy: 0.9087 - val_loss: 0.3601 - val_accuracy: 0.8441\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2464 - accuracy: 0.9175 - val_loss: 0.3521 - val_accuracy: 0.8471\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2252 - accuracy: 0.9261 - val_loss: 0.3485 - val_accuracy: 0.8472\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2068 - accuracy: 0.9340 - val_loss: 0.3453 - val_accuracy: 0.8489\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1902 - accuracy: 0.9399 - val_loss: 0.3438 - val_accuracy: 0.8499\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1753 - accuracy: 0.9461 - val_loss: 0.3433 - val_accuracy: 0.8506\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1617 - accuracy: 0.9511 - val_loss: 0.3453 - val_accuracy: 0.8521\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1495 - accuracy: 0.9551 - val_loss: 0.3472 - val_accuracy: 0.8508\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1383 - accuracy: 0.9595 - val_loss: 0.3506 - val_accuracy: 0.8492\n"
     ]
    }
   ],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 1s - loss: 0.3721 - accuracy: 0.8387\n",
      "[0.3721238970756531, 0.8387200236320496]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 모델구성을 위한 데이터 분석 및 가공\n",
    "- 데이터셋 내 문장 길이 분포\n",
    "- 적절한 최대 문장 길이 지정\n",
    "- keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 모델구성 및 validation set 구성\n",
    "- 모델은 3가지 이상 다양하게 구성하여 실험해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 모델 훈련 개시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Loss, Accuracy 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) 한국어 Word2Vec 임베딩 활용하여 성능개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 제출\n",
    "\n",
    "### 프로젝트 루브릭 : 아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "### 평가문항 : 상세기준\n",
    "\n",
    "1. 다양한 방법으로 Text Classification 태스크를 성공적으로 구현하였다.\n",
    ": 3가지 이상의 모델이 성공적으로 시도됨\n",
    "2. gensim을 활용하여 자체학습된 혹은 사전학습된 임베딩 레이어를 분석하였다.\n",
    ": gensim의 유사단어 찾기를 활용하여 자체학습한 임베딩과 사전학습 임베딩을 적절히 분석함\n",
    "3. 한국어 Word2Vec을 활용하여 가시적인 성능향상을 달성했다.\n",
    ": 네이버 영화리뷰 데이터 감성분석 정확도를 90% 이상 달성함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
